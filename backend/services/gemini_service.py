
import logging
import google.generativeai as genai
from core.config import settings

logger = logging.getLogger(__name__)

class GeminiService:
    def __init__(self):
        if settings.GEMINI_API_KEY:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            # Modelo Base (Eficiente para transcripci√≥n y extracci√≥n)
            self.basic_model = genai.GenerativeModel('gemini-2.0-flash-lite')
            # Modelo Razonamiento (Avanzado para causas de muerte)
            self.reasoning_model = genai.GenerativeModel('gemini-3-flash-preview')
            logger.info("‚úÖ Gemini Service h√≠brido inicializado (v2.0 Lite + v3 Flash Preview)")
        else:
            self.basic_model = None
            self.reasoning_model = None
            logger.warning("‚ö†Ô∏è GEMINI_API_KEY no configurada.")

    async def transcribe_audio(self, audio_path: str) -> str:
        """
        Transcribe audio utilizando Gemini 1.5 Flash (Multimodal).
        Sube el archivo a la API de Gemini y solicita la transcripci√≥n.
        """
        if not self.basic_model:
            raise ValueError("Gemini no est√° configurado. Verifica GEMINI_API_KEY.")

        try:
            logger.info(f"üì§ Subiendo audio a Gemini: {audio_path}")
            # Subir archivo usando la API de File
            audio_file = genai.upload_file(path=audio_path)
            
            # Esperar a que el archivo est√© en estado ACTIVE
            import time
            max_wait = 30  # m√°ximo 30 segundos
            wait_time = 0
            while audio_file.state.name == "PROCESSING" and wait_time < max_wait:
                logger.info(f"‚è≥ Esperando que archivo est√© listo... ({wait_time}s)")
                time.sleep(2)
                wait_time += 2
                audio_file = genai.get_file(audio_file.name)
            
            if audio_file.state.name != "ACTIVE":
                raise ValueError(f"Archivo no est√° activo despu√©s de {max_wait}s: {audio_file.state.name}")
            
            # Prompt para transcripci√≥n m√©dica precisa
            prompt = """
            Act√∫a como un transcriptor m√©dico experto forense.
            Escucha atentamente este audio de una necropsia y transcr√≠belo textualmente.
            Mant√©n la terminolog√≠a m√©dica exacta.
            Si hay pausas o ruidos, ign√≥ralos.
            Devuelve SOLO el texto transcrito, sin formato markdown ni comentarios.
            """

            logger.info("üß† Generando transcripci√≥n con Gemini...")
            
            # Retry Logic para 429 Resource Exhausted
            import time
            max_retries = 3
            base_delay = 2
            
            for attempt in range(max_retries + 1):
                try:
                    response = self.basic_model.generate_content([prompt, audio_file])
                    text = response.text
                    logger.info(f"‚úÖ Transcripci√≥n Gemini completada ({len(text)} caracteres)")
                    return text
                except Exception as e:
                    if "429" in str(e) and attempt < max_retries:
                        sleep_time = base_delay * (2 ** attempt)
                        logger.warning(f"‚ö†Ô∏è Cuota excedida (429). Reintentando en {sleep_time}s... (Intento {attempt + 1}/{max_retries})")
                        time.sleep(sleep_time)
                    else:
                        raise e

        except Exception as e:
            logger.error(f"‚ùå Error en transcripci√≥n Gemini: {e}")
            raise

    async def extract_entities(self, text: str) -> dict:
        """
        Extrae entidades m√©dico-legales del texto usando Gemini.
        Utiliza la estructura de campos v2.0 del protocolo IMLCF.
        """
        if not self.basic_model:
            raise ValueError("Gemini no est√° configurado.")

        prompt = f"""
Act√∫a como un experto forense peruano del IMLCF. Analiza el texto de necropsia y extrae informaci√≥n estructurada.

TEXTO DEL DICTADO:
"{text}"

INSTRUCCIONES:
1. Extrae "entities": lista de objetos con "text" y "type" (ORGAN, WEIGHT, MEASUREMENT, LESION_TYPE, CONDITION, PERSON, AGE, SEX)
2. Extrae "mapped_fields": diccionario con rutas de campo y valores

ESTRUCTURA DE CAMPOS (usar estas rutas exactas):

DATOS GENERALES:
- "datos_generales.numero_informe": n√∫mero de protocolo/informe
- "datos_generales.fallecido.nombre": nombre del fallecido
- "datos_generales.fallecido.apellido_paterno": apellido paterno
- "datos_generales.fallecido.apellido_materno": apellido materno  
- "datos_generales.fallecido.edad": edad (n√∫mero)
- "datos_generales.fallecido.sexo": "M" o "F"

FEN√ìMENOS CADAV√âRICOS:
- "fenomenos_cadavericos.livideces.observaciones": descripci√≥n de livideces
- "fenomenos_cadavericos.rigidez.observaciones": descripci√≥n de rigidez
- "fenomenos_cadavericos.tiempo_muerte_horas": tiempo estimado de muerte

EXAMEN INTERNO CABEZA:
- "examen_interno_cabeza.encefalo.peso": peso en gramos (n√∫mero)
- "examen_interno_cabeza.encefalo.descripcion": descripci√≥n

EXAMEN INTERNO T√ìRAX:
- "examen_interno_torax.pulmones.derecho.peso": peso en gramos (n√∫mero)
- "examen_interno_torax.pulmones.derecho.descripcion": descripci√≥n
- "examen_interno_torax.pulmones.izquierdo.peso": peso en gramos (n√∫mero)
- "examen_interno_torax.pulmones.izquierdo.descripcion": descripci√≥n
- "examen_interno_torax.corazon.peso": peso en gramos (n√∫mero)
- "examen_interno_torax.corazon.descripcion": descripci√≥n

EXAMEN INTERNO ABDOMEN:
- "examen_interno_abdomen.higado.peso": peso en gramos (n√∫mero)
- "examen_interno_abdomen.higado.descripcion": descripci√≥n
- "examen_interno_abdomen.bazo.peso": peso en gramos (n√∫mero)
- "examen_interno_abdomen.rinones.derecho.peso": peso en gramos (n√∫mero)
- "examen_interno_abdomen.rinones.izquierdo.peso": peso en gramos (n√∫mero)

CAUSAS DE MUERTE:
- "causas_muerte.diagnostico_presuntivo.causa_final.texto": causa final
- "causas_muerte.diagnostico_presuntivo.causa_basica.texto": causa b√°sica

EJEMPLO de respuesta:
{{
  "entities": [
    {{"text": "Juan Rodr√≠guez", "type": "PERSON"}},
    {{"text": "23 a√±os", "type": "AGE"}},
    {{"text": "masculino", "type": "SEX"}}
  ],
  "mapped_fields": {{
    "datos_generales.fallecido.nombre": "Juan",
    "datos_generales.fallecido.apellido_paterno": "Rodr√≠guez",
    "datos_generales.fallecido.edad": 23,
    "datos_generales.fallecido.sexo": "M"
  }}
}}

Responde SOLO con JSON v√°lido, sin markdown ni comentarios.
"""
        
        try:
            logger.info("üîç Extrayendo entidades v2.0 con Gemini...")
            # Retry Logic para 429 Resource Exhausted
            import time
            max_retries = 3
            base_delay = 2
            
            for attempt in range(max_retries + 1):
                try:
                    response = self.basic_model.generate_content(prompt)
                    # Limpiar posible markdown ```json ... ```
                    clean_text = response.text.replace("```json", "").replace("```", "").strip()
                    import json
                    result = json.loads(clean_text)
                    logger.info(f"‚úÖ NER v2.0: {len(result.get('mapped_fields', {}))} campos extra√≠dos")
                    return result
                except Exception as e:
                    if "429" in str(e) and attempt < max_retries:
                        sleep_time = base_delay * (2 ** attempt)
                        logger.warning(f"‚ö†Ô∏è Cuota NER excedida (429). Reintentando en {sleep_time}s... (Intento {attempt + 1}/{max_retries})")
                        time.sleep(sleep_time)
                    else:
                        raise e
        except Exception as e:
            return {"entities": [], "mapped_fields": {}}

    async def analyze_death_cause(self, findings_text: str) -> dict:
        """
        Utiliza Gemini 3 (Reasoning Model) para deducir la causa de muerte
        basada en los hallazgos transcritos.
        """
        if not self.reasoning_model:
            raise ValueError("Gemini 3 (Reasoning) no est√° configurado.")

        prompt = f"""
        Act√∫a como un M√©dico Legista Senior.
        Analiza los siguientes HALLAZGOS DE NECROPSIA y razona paso a paso para determinar la Causa de Muerte.
        Utiliza tu capacidad de razonamiento profundo para conectar lesiones y patolog√≠as.

        HALLAZGOS:
        "{findings_text}"
        
        Tu tarea:
        1. Identificar la Causa Final (mecanismo que produjo la muerte directa).
        2. Identificar la Causa Intermedia (consecuencia patol√≥gica).
        3. Identificar la Causa B√°sica (evento o enfermedad inicial).
        4. Proveer un "razonamiento_clinico" detallado justificando tu deducci√≥n.

        Responde SOLO en JSON con este formato:
        {{
            "causa_final": "...",
            "causa_intermedia": "...",
            "causa_basica": "...",
            "razonamiento_clinico": "..."
        }}
        """

        try:
            logger.info("üß† Gemini 3 Thinking: Analizando causa de muerte...")
            
            # Retry Logic
            import time
            max_retries = 3
            base_delay = 2
            
            for attempt in range(max_retries + 1):
                try:
                    response = self.reasoning_model.generate_content(prompt)
                    clean_text = response.text.replace("```json", "").replace("```", "").strip()
                    import json
                    result = json.loads(clean_text)
                    logger.info("‚úÖ Gemini 3: An√°lisis completado.")
                    return result
                except Exception as e:
                    if "429" in str(e) and attempt < max_retries:
                        sleep_time = base_delay * (2 ** attempt)
                        logger.warning(f"‚ö†Ô∏è Gemini 3 Busy (429). Reintentando en {sleep_time}s...")
                        time.sleep(sleep_time)
                    else:
                        raise e
                        
        except Exception as e:
            logger.error(f"‚ùå Error Gemini 3 Reasoning: {e}")
            raise

print("Gemini Service Loaded")
